# -*- coding: utf-8 -*-
"""Prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IVpQAVSAqMo58XdbtGvv3FWc2tzcyGIx
"""

import requests
standings_url = "https://soccer365.ru/competitions/13/results/"
data = requests.get(standings_url)
from bs4 import BeautifulSoup
import pandas as pd
import numpy as np

from google.colab import files
from datetime import datetime

"""**1) Parsing of the wesite**"""

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'
}


columns = ["URL","Команда_1", "Голы_1", "Команда_2", "Голы_2", \
                             "xG_1","xG_2", "Удары_1" ,"Удары_2","Удары в створ_1",\
                             "Удары в створ_2", "Блок-но ударов_1", "Блок-но ударов_2", \
                             "Сейвы_1", "Сейвы_2", "Владение %_1", "Владение %_2", \
                             "Угловые_1", "Угловые_2", "Нарушения_1", "Нарушения_2",\
                             "Офсайды_1","Офсайды_2","Желтые карточки_1","Желтые карточки_2",\
                             "Красные карточки_1","Красные карточки_2","Атаки_1","Атаки_2",\
                             "Опасные атаки_1","Опасные атаки_2","Передачи_1",\
                             "Передачи_2","Точность передач %_1","Точность передач %_2","Штрафные удары_1",\
                             "Штрафные удары_2","Вбрасывания_1","Вбрасывания_2","Навесы_1",\
                             "Навесы_2","Отборы_1","Отборы_2","Раунд","Дата","Время",\
                             "Кэф_1","Кэф_х","Кэф_2","Стадион", "Градусы", "Погода",\
                             "Зрители"]
def parse_match_stats(url):
    # downloading content of the page
    page = requests.get(url,headers=headers)
    soup = BeautifulSoup(page.content, 'html.parser')

    # parsing teams names and scores
    team1 = soup.find('div', class_='live_game left').find('a').text
    score1 = soup.find('div', class_='live_game left').find('span').text
    team2 = soup.find('div', class_='live_game right').find('a').text
    score2 = soup.find('div', class_='live_game right').find('span').text

    # parsing match stats
    stats_items = soup.find_all('div', class_='stats_item')
    match_stats = {
        'URL': url,
        'Команда_1': team1,
        'Голы_1': score1,
        'Команда_2': team2,
        'Голы_2': score2,
    }
    for item in stats_items:
        title = item.find('div', class_='stats_title').text.strip()
        values = item.find_all('div', class_='stats_inf')
        match_stats[f"{title}_1"] = float(values[0].text.strip())
        match_stats[f"{title}_2"] = float(values[1].text.strip())

    # parsing tour, date and time
    game_event_header = soup.find('div', id="game_events").find('h2').text
    details = game_event_header.split(',')
    match_stats['Раунд'] = details[1].strip()
    date_time = details[3].strip().split(' ')
    match_stats['Дата'] = date_time[0]
    match_stats['Время'] = date_time[1]


    # parsing bookm coef
    odds_row = soup.find('table', class_='adv_kef_wgt').find('tr', class_='adv_kef_wgt_odd')
    odds = odds_row.find_all('td')[1:4]  # Пропускаем первый td, так как он содержит только изображение
    match_stats['Кэф_1'] = float(odds[0].find('span', class_='koeff').text)
    match_stats['Кэф_х'] = float(odds[1].find('span', class_='koeff').text)
    match_stats['Кэф_2'] = float(odds[2].find('span', class_='koeff').text)


    # parsing add details
    preview_block = soup.find('div', id='preview').find('div', class_='block_body')

    # name of the stdium
    stadium_block = preview_block.find('div', class_='preview_item st')
    match_stats['Стадион'] = stadium_block.find('a').text

    # weather
    weather_block = stadium_block.find('div', class_='img16 weath_tmp')
    if weather_block:
        weather_temp_element = weather_block.find('span', class_='red')
        if weather_temp_element:
            weather_temp = weather_temp_element.text
        else:
            weather_temp = "Not specified"

        weather_desc_elements = stadium_block.find_all('span', class_='min_gray')
        if len(weather_desc_elements) > 1:
            weather_desc = weather_desc_elements[1].text
        else:
            weather_desc = "Not specified"

        match_stats['Градусы'] = weather_temp
        match_stats['Погода'] = weather_desc
    else:
        match_stats['Градусы'] = "Not specified"
        match_stats['Погода'] = "Not specified"


    # weather_block = stadium_block.find('div', class_='img16 weath_tmp')
    # if weather_block:
    #     weather_temp = weather_block.find('span', class_='red').text
    #     weather_desc_elements = stadium_block.find_all('span', class_='min_gray')
    #     weather_desc = weather_desc_elements[1].text if len(weather_desc_elements) > 1 else "Not specified"
    #     match_stats['Градусы'] = weather_temp
    #     match_stats['Погода'] = weather_desc

  # attendance
    preview_items = preview_block.find_all('div', class_='preview_item')
    for item in preview_items:
        if 'Зрителей' in item.text:
            audience_number = ''.join(filter(str.isdigit, item.text))
            match_stats['Зрители'] = audience_number
            break


    for i in columns:
      if i not in match_stats:
        match_stats[i] = pd.NA
    return match_stats

"""теперь нам нужно вытащить ссылки на каждый матч:

"""

def extract_game_links(url):
  page = requests.get(url)
  soup = BeautifulSoup(page.content, 'html.parser')

  game_blocks = soup.find_all('div', class_='game_block')

  links = []
  for block in game_blocks:
    game_link = block.find('a', class_= 'game_link')
    if game_link and 'href' in game_link.attrs:
      links.append('https://soccer365.ru' + game_link['href'])
  return links

links = extract_game_links(standings_url)
#print(links)

"""Теперь у нас есть ссылки на каждый отдельный матч, по которым мы сможем смотреть подробную статистику каждой игры. Итерируясь по каждому айтему из массива links, мы вызываем функцию parse_match_stats и сохраняем это в df_dict. Теперь у нас есть готовый DataFrame для работы"""

df = pd.DataFrame()
links = extract_game_links(standings_url)
for link in links:
  try:
    df_dict = pd.DataFrame([parse_match_stats(link)])
    df = pd.concat([df,df_dict], ignore_index = True)
  except:
    print(f"link error: {link}")

"""Create a .csv and download on the computer"""

df.to_csv("rpl_stats", sep=',')

# files.download('/content/rpl_stats')

df.shape

df = pd.read_csv('rpl_stats', index_col = 0)
df.head(5)

"""**2) Data preparation**

looking at the data types
"""

df.info()

"""some columns are in inconvinient format

"""

df = df.drop('URL', axis = 1) # столбец был изначально отладочный, поэтому его можно отбросить
df.head()

"""separate the number of the tour from the word 'тур'"""

df['Раунд'] = df['Раунд'].apply(lambda x: int(x.split('-')[0]))

df['Раунд']

"""
transform date into pandas datetime"""

df['Дата'] = pd.to_datetime(df['Дата'], format='mixed')
df.dtypes['Дата']
df['Дата']

df['Время'] = pd.to_datetime(df['Время'], format = '%H:%M').dt.time

df['Градусы'].values

"""making weather data more convinient"""

# df['Градусы']= df['Градусы'].apply(lambda x: int(x[1:-2]))

def convert_to_int(value):
    try:
        cleaned_value = value[1:-2]  # Extract the part of the string that should represent the integer
        return int(cleaned_value)
    except (ValueError, TypeError):
        return None  # Return None for values that cannot be converted to integers

df['Градусы'] = df['Градусы'].apply(lambda x: convert_to_int(x))

"""It seems that the information about which stadium we have is not very useful in the form in which it is. It is clear from intuitive assumptions that if a team plays at home, then it is on its own territory, therefore it plays better. Therefore, from our stadium attribute, we need to learn to understand whether she is playing at home or away. At the same time, there are non-native stadiums of the teams, we will leave them for now as guest stadiums for both teams.
You need to parse the stadiums page, go to each stadium and get two dictionaries, for example, with average attendance and a list of teams for which the stadium is native.
"""

standing_url = 'https://soccer365.ru/competitions/13/stadiums/'

def extract_stadium_links(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'
    }
    response = requests.get(url, headers=headers)
    soup = bs(response.content, 'html.parser')

    # parsing of the sadiums
    stadium_data = []
    tr_elements = soup.find_all('tr')
    for tr in tr_elements:
        td_elements = tr.find_all('td')
        if len(td_elements) > 5:  # let's make sure that the table row contains a sufficient number of elements
            stadium_info = td_elements[1].find('a')
            if stadium_info:
                stadium_name = stadium_info.text.strip()
                stadium_link = 'https://soccer365.ru/' + stadium_info['href']
                attendance = td_elements[5].text.strip()  # Attendance from the sixth <td>
                stadium_data.append({
                    'Стадион': stadium_name,
                    'Ссылка на стадион': stadium_link,
                    'Посещаемость': attendance
                })

    return stadium_data

from bs4 import BeautifulSoup as bs

parse_data = extract_stadium_links(standing_url)
stadium_df = pd.DataFrame(parse_data)
stadium_df

def get_teams_from_stadium(url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.121 Safari/537.36'
    }
    response = requests.get(url, headers=headers)
    soup = bs(response.content, 'html.parser')

    # We find the elements that contain information about the commands
    teams = []
    team_elements = soup.find_all('div', class_='img16')
    for team_element in team_elements:
        team_link = team_element.find('a')
        if team_link:
            team_name = team_link.text.strip()
            teams.append(team_name)

    # If the list of commands is empty, check if there is an alternative block to search for
    if not teams:
        teams_td = soup.find('td', class_='params_key', text='Команды').find_next_sibling('td')
        if teams_td:
            for team in teams_td.find_all('a'):
                teams.append(team.text.strip())

    return teams

def update_stadiums_df(df):
    df['Команды'] = df['Ссылка на стадион'].apply(get_teams_from_stadium)
    return df

stadium_df = update_stadiums_df(stadium_df)
stadium_df

def update_main_df(df,stadium_df):
  stadium_teams ={row['Стадион']:row['Команды'] for index, row in stadium_df.iterrows()}

  def is_home_team(stadium,team):
    if stadium in stadium_teams and team in stadium_teams[stadium]:
      return 1
    return 0
  df['Дома_1'] = df.apply(lambda x:is_home_team(x['Стадион'], x['Команда_1']), axis =1)
  df['Дома_2'] = df.apply(lambda x:is_home_team(x['Стадион'], x['Команда_2']), axis = 1)
  return df
update_main_df(df,stadium_df)

df['Дома_1'].values

# stadium_df['Посещаемость'] = stadium_df['Посещаемость'].apply(lambda x: float(x.replace(",",'')))
stadium_df['Посещаемость'] = stadium_df['Посещаемость'].apply(lambda x: float(x.replace(",",'')) if x else 0)

def fill_audience_with_variation(df, stadium_df):
    # creating a dictionary where the key is the name of the stadium, and the value is attendance
    attendance_dict = stadium_df.set_index('Стадион')['Посещаемость'].to_dict()

    #  function to fill in the audience
    def fill_audience(row):
        if pd.isna(row['Зрители']) and row['Стадион'] in attendance_dict:
            # We get the basic attendance
            base_attendance = attendance_dict[row['Стадион']]
            # We generate a random increase from 10% to 15%
            increase = np.random.uniform(0.1, 0.15)
            # increasing attendance
            adjusted_attendance = int(base_attendance * (1 + increase))
            return adjusted_attendance
        else:
            return row['Зрители']

    # apply the func to each row in DataFrame
    df['Зрители'] = df.apply(fill_audience, axis=1)
    return df
fill_audience_with_variation(df, stadium_df)

df.info()

df = df.drop('Стадион', axis = 1)

"""We need to fill in the missing fields of overhangs, selections, gears, xG, gear accuracy
To fill in the missing fields, let's write a tricky function. Since we are dealing with quantitative features, we can calculate for each command the average of the missing parameter, and then the missing value for them. That is, we group the missing columns by commands, count the signs, and then for incomplete rows we count the parameter we need.
"""

def fill_missing_values(df, team_columns, stats_columns):
    # For each team and each statistical column
    for team_col in team_columns:
        for stats_col in stats_columns:
            # We calculate the average values for each team
            mean_stats_per_team = df.groupby(team_col)[stats_col].mean()

            # function for filling in NaN values
            def fill_na_with_team_avg(row):
                if pd.isna(row[stats_col]):
                    return mean_stats_per_team.get(row[team_col], np.nan)
                return row[stats_col]

            # function to fill in the NaN
            df[stats_col] = df.apply(fill_na_with_team_avg, axis=1)

    return df

team_columns = ['Команда_1', 'Команда_2']
stats_columns = df.loc[:,df.dtypes != object].columns
df = fill_missing_values(df, team_columns, stats_columns)

df.isna().sum()

df.info()

#add the column with match result
def define_match_result(row):
    if row['Голы_1'] > row['Голы_2']:
        return 1  # win of the team 1
    elif row['Голы_1'] < row['Голы_2']:
        return 2  # win of the team 2
    else:
        return 0  # draw

df['Таргет'] = df.apply(define_match_result, axis=1)

df.head()

df.to_csv("final_rpl.csv", sep =';')

#files.download('/content/final_rpl.csv')

import pandas as pd

df = pd.read_csv('final_rpl.csv', sep=';', index_col = 0)

df.shape

df_1 = df.copy()
df_1 = pd.get_dummies(df_1, columns = ['Погода'])
df_1['Дата'] = pd.to_datetime(df_1['Дата'])
df_1['Год'] = df_1['Дата'].dt.year
df_1['Месяц'] = df_1['Дата'].dt.month
df_1['День'] = df_1['Дата'].dt.day
df_1 = df_1.drop('Дата', axis = 1)
df_1['Время'] = pd.to_timedelta(df_1['Время']).dt.components.hours

df_1.info()

df_1.to_csv("df_1.csv", sep =';')

#files.download('/content/df_1.csv')

"""Let's try logistic regression To do this, encode the last signs, divide them into test and training samples and mix everything up a little. Also, to improve the convergence and quality of training, it is best to normalize the data, so we will use a standard scaler."""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

df_1_encoded = pd.get_dummies(df_1, columns=['Команда_1', 'Команда_2'])
X = df_1_encoded.drop('Таргет', axis = 1)
y = df_1_encoded['Таргет']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

"""Let's train our logistic regression"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score

model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)
model.fit(X_train_scaled, y_train)

y_pred = model.predict(X_test_scaled)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy score: {accuracy:.2f}")

print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

f1 = f1_score(y_test, y_pred, average= 'micro')
print(f"F1 Score: {f1}")

"""Now, for comparison, let's look at the results of the random forest model. Let's take, for example, 100 training trees and look at the accuracy. We will not mix it a second time, we have already done this before when preparing the data."""

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

model = RandomForestClassifier(n_estimators=100)
model.fit(X_train_scaled, y_train)
y_pred = model.predict(X_test_scaled)

accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average= 'micro')

print(f'Accuracy score: {accuracy:.2f}')
print(f"F1 Score: {f1}")

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import f1_score

base_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
rf_model = OneVsRestClassifier(base_model)
rf_model.fit(X_train_scaled, y_train)
y_pred = rf_model.predict(X_test_scaled)

accuracy = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average= 'micro')

print(f'Accuracy score: {accuracy:.2f}')
print(f"F1 Score: {f1}")

# print(classification_report(y_test, y_pred))
# print(confusion_matrix(y_test, y_pred))

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.multiclass import OneVsRestClassifier
import numpy as np
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt
import pandas as pd

y_bin = label_binarize(y, classes=np.unique(y))
X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.3, random_state=42)

clf = OneVsRestClassifier(LogisticRegression(solver='liblinear'))
clf.fit(X_train, y_train)
y_score = clf.predict_proba(X_test)
fpr = dict()
tpr = dict()
roc_auc = dict()
n_classes = y_bin.shape[1]

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

plt.figure()
colors = ['aqua', 'darkorange', 'cornflowerblue']
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f'ROC curve of class {i} (area = {roc_auc[i]:0.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic for Multi-class')
plt.legend(loc = "lower right")
plt.show()

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

#  time dimension for LSTM
X_scaled = np.expand_dims(X_scaled, axis=1)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

# Determining of LTSM model
lstm_model = Sequential()
lstm_model.add(LSTM(35, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(35))
lstm_model.add(Dropout(0.2))
lstm_model.add(Dense(3, activation='softmax'))

lstm_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
history = lstm_model.fit(X_train, y_train, epochs=35, batch_size=10, validation_split=0.3)

loss, accuracy = lstm_model.evaluate(X_test, y_test)
f1 = f1_score(y_test, y_pred, average= 'micro')


print(f'Accuracy score: {accuracy:.2f}')
print(f"F1 Score: {f1}")

# print(classification_report(y_test, y_pred))
# print(confusion_matrix(y_test, y_pred))

"""**3) Creating of a rating**

"""

df_for_rating = pd.read_csv('df_1.csv', sep=';', index_col = 0)
df_for_rating.head()

columns = ["Команда", "Кол-во матчей", "Голы", "Пропущенные голы", \
           "xG", "Удары", "Удары в створ",\
           "Блок-но ударов", \
           "Сейвы", "Владение %", \
           "Угловые", "Нарушения", \
           "Офсайды", "Желтые карточки", \
           "Красные карточки","Атаки",\
           "Опасные атаки","Передачи",\
           "Точность передач %","Штрафные удары",\
           "Вбрасывания","Навесы",\
           "Отборы", "Зрители"]

team_df = pd.DataFrame()
all_teams = set(df_for_rating['Команда_1']) | set(df_for_rating['Команда_2'])
for team in all_teams:
  team_data = {x:0 for x in columns}
  team_data['Команда'] = team
  for index, row in df_for_rating.iterrows():
    if row['Команда_1'] == team:
      for key in columns[2:-1]:
        if key == 'Пропущенные голы':
          team_data[key] += row['Голы_2']
        else:
          team_data[key] += row[key+'_1']
      team_data['Зрители'] += row['Зрители']
      team_data['Кол-во матчей'] += 1
    if row['Команда_2'] == team:
      for key in columns[2:-1]:
        if key == 'Пропущенные голы':
          team_data[key] += row['Голы_1']
        else:
          team_data[key] += row[key+'_2']
      team_data['Кол-во матчей'] += 1
      team_data['Зрители'] += row['Зрители']
  team_df = pd.concat([team_df, pd.DataFrame(team_data, index=[0])], ignore_index = True)

# Averaging percentages
team_df["Владение %"] = team_df["Владение %"] / team_df["Кол-во матчей"]
team_df["Точность передач %"] = team_df["Точность передач %"] / team_df["Кол-во матчей"]
team_df

"""Downloading of a file

"""

team_df.to_csv("team_df.csv", sep =';')


#files.download('/content/team_df.csv')

for col in team_df.select_dtypes(include=['float64']).columns:
    team_df[col] = team_df[col].round().astype(int)

coefficients = {
    "Голы" : 1,
    "Пропущенные голы" : -1,
    "xG" : 0.8,
    "Удары в створ" : 0.5,
    "Сейвы" : 1,
    "Владение %" : 1,
    "Желтые карточки" : -0.5,
    "Красные карточки" : -2,
    "Опасные атаки" : 1,
    "Точность передач %" : 1,
    "Штрафные удары" : 0.5,
    "Зрители": 1,
}

team_df["Rating"] = team_df['Голы'] * coefficients['Голы'] + team_df['Пропущенные голы'] * coefficients['Пропущенные голы'] + team_df['xG'] * coefficients['xG'] + team_df["Удары в створ"] * coefficients["Удары в створ"]
+ team_df['Сейвы'] * coefficients['Сейвы'] + team_df["Владение %"] * coefficients["Владение %"] + team_df["Желтые карточки"] * coefficients["Желтые карточки"]
+ team_df["Красные карточки"] * coefficients["Красные карточки"] + team_df["Опасные атаки"] * coefficients["Опасные атаки"]
+ team_df["Точность передач %"] * coefficients["Точность передач %"] + team_df["Штрафные удары"] * coefficients["Штрафные удары"]
+ team_df['Зрители'] * coefficients['Зрители']

rating_table = team_df[["Команда", "Rating"]].sort_values(by="Rating", ascending=False)
rating_table["Predicted Place"] = range(1, len(rating_table) + 1)

highscores_url = 'https://soccer365.ru/competitions/13/'
highscores_page = requests.get(highscores_url, headers=headers)
highscores_soup = BeautifulSoup(highscores_page.content, 'html.parser')

highscores = []
highscores_items = highscores_soup.find('table', 'stngs').find_all('div', class_='img16')
for item in highscores_items:
  team = item.find('a').text
  highscores.append(team)

rating_table['Real Place'] = [highscores.index(team) + 1 for team in rating_table['Команда']]
print(rating_table.to_string(index = 0))